{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python388jvsc74a57bd098b0a9b7b4eaaa670588a142fd0a9b87eaafe866f1db4228be72b4211d12040f",
   "display_name": "Python 3.8.8 64-bit ('base': conda)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "## Classify Trafic Signs image data using Keras CNN"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.optimizers import Adam\n",
    "from keras.utils.np_utils import to_categorical\n",
    "from keras.layers import Dropout, Flatten\n",
    "from keras.layers.convolutional import Conv2D, MaxPooling2D\n",
    "import pickle\n",
    "import pandas as pd\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clone the github repo for train, validation and test data\n",
    "!git clone https://bitbucket.org/jadslim/german-traffic-signs\n",
    "\n",
    "# Read the pickle files\n",
    "with open('german-traffic-signs/train.p', 'rb') as f:\n",
    "    train_data = pickle.load(f)\n",
    "\n",
    "with open('german-traffic-signs/valid.p', 'rb') as f:\n",
    "    val_data = pickle.load(f)\n",
    "\n",
    "with open('german-traffic-signs/test.p', 'rb') as f:\n",
    "    test_data = pickle.load(f)\n",
    "\n",
    "# Convert the dictionary to required array format for all the data\n",
    "X_train, y_train = train_data['features'], train_data['labels']\n",
    "X_val, y_val = val_data['features'], val_data['labels']\n",
    "X_test, y_test = test_data['features'], test_data['labels']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X_train.shape)\n",
    "print(X_val.shape)\n",
    "print(X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the input data\n",
    "assert(X_train.shape[0] == y_train.shape[0]), 'Train: The number of images are not equal to the number of labels'\n",
    "assert(X_val.shape[0] == y_val.shape[0]), 'Validation: The number of images are not equal to the number of labels'\n",
    "assert(X_test.shape[0] == y_test.shape[0]), 'Test: The number of images are not equal to the number of labels'\n",
    "assert(X_train.shape[1:] == (32, 32, 3)), \"Train: The dimensions of the images are not 32 x 32 x 3\"\n",
    "assert(X_val.shape[1:] == (32, 32, 3)), \"Train: The dimensions of the images are not 32 x 32 x 3\"\n",
    "assert(X_test.shape[1:] == (32, 32, 3)), \"Train: The dimensions of the images are not 32 x 32 x 3\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the csv file\n",
    "data = pd.read_csv('german-traffic-signs/signnames.csv')\n",
    "num_of_samples = []\n",
    "cols = 5\n",
    "num_classes = 43\n",
    "\n",
    "fig, axs = plt.subplots(nrows=num_classes, ncols=cols, figsize=(5, 50))\n",
    "fig.tight_layout()\n",
    "for i in range(cols):\n",
    "    for j, row in data.iterrows():\n",
    "        x_selected = X_train[y_train==j]\n",
    "        axs[j, i].imshow(x_selected[random.randint(0, (len(x_selected) - 1)), :, :], cmap=plt.get_cmap('gray'))\n",
    "        axs[j, i].axis('off')\n",
    "        if i == 2:\n",
    "            axs[j, i].set_title(str(j) + '-' + row['SignName'])\n",
    "            num_of_samples.append(len(x_selected))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " print(num_of_samples)\n",
    " plt.figure(figsize=(12, 4))\n",
    " plt.bar(range(num_classes), num_of_samples)\n",
    " plt.title('Distribution of the train dataset')\n",
    " plt.xlabel('Class number')\n",
    " plt.ylabel('Number of images')\n",
    " plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "plt.imshow(X_train[1000])\n",
    "plt.axis('off')\n",
    "print(X_train[1000].shape)\n",
    "print(y_train[1000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def grayscale(img):\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    return img\n",
    "\n",
    "img = grayscale(X_train[1000])\n",
    "print(img.shape)\n",
    "plt.imshow(img, cmap='gray_r')\n",
    "plt.axis('off')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def equalize(img):\n",
    "    img = cv2.equalizeHist(img)\n",
    "    return img\n",
    "\n",
    "img = equalize(img)\n",
    "print(img.shape)\n",
    "plt.imshow(img, cmap='gray_r')\n",
    "plt.axis('off')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessing(img):\n",
    "    img = grayscale(img)\n",
    "    img = equalize(img)\n",
    "    img = img/255\n",
    "    return img\n",
    "\n",
    "X_train = np.array(list(map(preprocessing, X_train)))\n",
    "X_val = np.array(list(map(preprocessing, X_val)))\n",
    "X_test = np.array(list(map(preprocessing, X_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(X_train[random.randint(0, len(X_train) - 1)], cmap='gray_r')\n",
    "plt.axis('off')\n",
    "print(X_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train.reshape(34799, 32, 32, 1)\n",
    "X_val = X_val.reshape(4410, 32, 32, 1)\n",
    "X_test = X_test.reshape(12630, 32, 32, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = to_categorical(y_train, 43)\n",
    "y_val = to_categorical(y_val, 43)\n",
    "y_test = to_categorical(y_test, 43)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def leNet_model():\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(60, (5, 5), input_shape=(32, 32, 1), activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Conv2D(30, (3, 3), activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(500, activation='relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(num_classes, activation='softmax'))\n",
    "    model.compile(Adam(lr=0.001), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = leNet_model()\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(X_train, y_train, epochs=10, validation_data=(X_val, y_val), batch_size=400, verbose=1, shuffle=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.legend(['training', 'validation'])\n",
    "plt.title('Loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(history.history['accuracy'])\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "plt.legend(['training', 'validation'])\n",
    "plt.title('Accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score = model.evaluate(X_test, y_test, verbose=0)\n",
    "print(\"Test Score: \", score[0])\n",
    "print(\"Test Accuracy: \", score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modifications to improve accuracy: \n",
    "# Decrease Learning Rate from 0.01 to 0.001, \n",
    "# Increase the Convolutional filters from 30 to 60 and 15 to 30, \n",
    "# Add more Convolutional layers before each Pooling layer, \n",
    "# Add Dropout layer after 2nd Pool layer to prevent overfitting\n",
    "def modified_model():\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(60, (5, 5), input_shape=(32, 32, 1), activation='relu'))\n",
    "    model.add(Conv2D(60, (3, 3), activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "    model.add(Conv2D(30, (3, 3), activation='relu'))\n",
    "    model.add(Conv2D(30, (3, 3), activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Dropout(0.5))\n",
    "\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(500, activation='relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(num_classes, activation='softmax'))\n",
    "    model.compile(Adam(lr=0.001), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "model_2 = modified_model()\n",
    "print(model_2.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history_2 = model_2.fit(X_train, y_train, epochs=10, validation_data=(X_val, y_val), batch_size=400, verbose=1, shuffle=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(history_2.history['loss'])\n",
    "plt.plot(history_2.history['val_loss'])\n",
    "plt.legend(['training', 'validation'])\n",
    "plt.title('Loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(history_2.history['accuracy'])\n",
    "plt.plot(history_2.history['val_accuracy'])\n",
    "plt.legend(['training', 'validation'])\n",
    "plt.title('Accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score_2 = model_2.evaluate(X_test, y_test, verbose=0)\n",
    "print(\"Test Score: \", score_2[0])\n",
    "print(\"Test Accuracy: \", score_2[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}